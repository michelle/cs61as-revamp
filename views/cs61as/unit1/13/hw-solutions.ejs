<pre>
CS61A	Week 13 solutions

HOMEWORK:
---------

Analyzing Evaluator
===================

4.22  LET in analyzing evaluator

This is easy, given the hint about 4.6.  We don't have to change the
procedure LET->COMBINATION we wrote for that exercise; since it deals
entirely with the expression, and not with the values of variables,
all of its work can be done in the analysis phase.  All we do is
change this COND clause in EVAL:

	((let? exp) (eval (let->combination exp) env))

to this COND clause in ANALYZE:

	((let? exp) (analyze (let->combination exp)))


4.23  Efficiency of analyze-sequence

For a sequence with just one expression, the book's version does the
following analysis:  First, the body of analyze-sequence is the LET.
Suppose that the result of analyzing the one expression is PROC.
Then the variable PROCS will have as its value a list whose only
element is PROC.  That's not null, so (still in the analysis part)
we call (LOOP PROC '()).  In LOOP, since (in this case) REST-PROCS
is null, LOOP just returns PROC.  So if the analysis of EXP gives
PROC, then the analysis of (BEGIN EXP) also gives PROC.

In the same one-expression case, Alyssa's version returns
	(lambda (env) (execute-sequence (list PROC) env))
So every time this execution procedure is called, execute-sequence
will check that (cdr procs) is empty, which it is, and then
calls PROC with the environment as its argument.  This test of
(null? (cdr procs)) is done for every execution, whereas in the
book's version it was done just once.

How about the two-expression case.  Suppose that the analysis of
EXP1 gives PROC1, and the anaylsis of EXP2 gives PROC2.  The book's
version will call, in effect, (loop PROC1 (list PROC2)).  This
in turn calls (sequentially PROC1 PROC2), which returns
	(lambda (env) (PROC1 env) (PROC2 env))
as the execution procedure.  (There is a recursive call to LOOP,
but it doesn't change the result, because this time the second
argument is null.)

Alyssa's version makes the execution procedure be
	(lambda (env) (execute-sequence (list PROC1 PROC2) env)))
which in effect means
	(lambda (env)
	  (cond ((null? (list PROC2)) ...)
		(else (PROC1 env)
		      (cond ((null? '()) (PROC2 env)) ...))))
Each time this is executed, we do two unnecessary checks for
the nullness of a list -- unnecessary because we already knew
while doing the analysis how many expressions are in the sequence.


4.24  How fast?

Hint:  You'll get the most dramatic results when an expression
is evaluated over and over, i.e., with a recursive procedure.



Lazy Evaluator
==============

4.25  UNLESS in normal vs. applicative order

In ordinary (applicative order) Scheme, this version of FACTORIAL
will be an infinite loop, because the argument subexpression
(* n (factorial (- n 1))) is evaluated before UNLESS is called,
whether or not n is 1.

In normal order Scheme it'll work fine, because the argument
subexpressions aren't evaluated until they're needed.  What
will actually happen is that each use of the special form IF
within UNLESS will force the computation of (= n 1), but
no multiplications will happen until the evaluator tries to
print the result.  In effect, (factorial 5) returns the thunk
        (lambda () (* 5 (* 4 (* 3 (* 2 (* 1 1))))))
and that gets evaluated just in time to print the answer.


4.26  Normal order vs. special forms

For Ben's side of the argument we must implement UNLESS as a
derived expression:

(define (unless->if exp)
  (make-if (unless-predicate exp)
	   (unless-consequent exp)
	   (unless-alternative exp)))

(define unless-predicate cadr)
(define unless-alternative caddr)
(define unless-consequent cadddr)

Notice that we reversed the order of the last two subexpressions in
the call to make-if.

Then we just add a clause
        ((unless? exp) (eval (unless->if exp) env))
to the ordinary metacircular evaluator, or
        ((unless? exp) (analyze (unless->if exp)))
to the analyzing evaluator.

For Alyssa's side of the argument, we need a case in which it's useful to
have a Scheme special form available as an ordinary procedure.  The only
thing we can do with ordinary procedures but not with special forms is use
them as arguments to higher-order procedures.  An example using UNLESS will
be a little strained, so first we'll look at a more common situation
involving a different special form, namely AND.  We'd like to be able to say

(define (all-true? tf-list)
  (accumulate and tf-list))

Now, here's the strained example using UNLESS:  Suppose we have a list of
true-false values and we'd like to add up the number of true ones.  Here's a
somewhat strange way to do it:

(define zero-list (cons 0 '()))
(set-cdr! zero-list zero-list)

(define one-list (cons 1 '()))
(set-cdr! one-list one-list)

(define (howmany-true tf-list)
  (apply + (map unless tf-list zero-list one-list)))

Zero-list is an infinite list of zeros; one-list is an infinite list
of ones.  We make use of the fact that MAP's end test is that its
first argument is empty, so MAP will return a list the same size as
the argument tf-list.  For example, if tf-list is
        (#t #t #f #t)
then map will return
        (1 1 0 1)
created, in effect, this way:
        (list (unless #t 0 1)
	      (unless #t 0 1)
	      (unless #f 0 1)
	      (unless #t 0 1))
And so + will return 3, the number of trues in the list.


4.28  Why force the operator of a combination?

Thunks are made by APPLY, representing arguments to defined procedures.
So we need a case in which the operator of an expression is the returned
argument of a defined procedure.  Here's an example:

(((lambda (a b) a) + -) 2 3)


4.30  Side effects vs. lazy evaluation

(a) Why is Ben right about for-each?

For-each includes the expression (proc (car items)).  As we
discussed in ex. 4.28, the lazy evaluator will force the
operator of that expression, i.e., PROC.  The resulting
procedure has two invocations of primitives, NEWLINE and
DISPLAY.  Evaluating those invocations will actually call
the procedures, and the argument X to DISPLAY will be
evaluated because DISPLAY is primitive.

(b) What happens in Cy's example?

First of all, in ordinary Scheme both (p1 1) and (p2 1) give
the result (1 2).

With the book's version of eval-sequence, (p1 1) is still (1 2)
but (p2 1) is 1, because the SET! will never happen.  The
subprocedure P has a two-expression sequence as its body, and
the first expression will never be evaluated.

With Cy's version both (p1 1) and (p2 1) are (1 2), as in
ordinary Scheme.

(c) Why doesn't Cy's version change part (a)?

The change isn't as dramatic as it may seem.  Don't think that
the original eval-sequence calls delay-it!  It calls EVAL, and
most of the time EVAL does return a value, not a thunk.  In
particular, a procedure call is carried out right away; it's
only the *arguments* to the procedure that are delayed.  That's
why Cy had to use a weird example in which a SET! expression
is used as an argument to a procedure in order to get the wrong
result.

(d) What's the right thing to do?

The combination of lazy evaluation and mutation in the same language
is so confusing that programmers would be surprised no matter which
choice we made.  That's why, in the real world, the languages that
use normal order evaluation are *functional* languages in which
there is no mutation or other side effects.  In such a language,
there are no sequences (if there are no side effects, what would
be the point?) and the problem doesn't arise.

But if we really wanted to have a normal-order Scheme, we'd
probably want to change the semantics of the language as little
as possible -- programs that work in ordinary Scheme should work
in lazy Scheme too.  So I think Cy is right.


4.32  Lazy trees

One possibility is to use doubly-lazy lists as an alternative to
interleaving, when dealing with a naturally two-dimensional problem.
For example, to get pairs of integers, we could say

(define (pairs a b)
  (cons (map (lambda (x) (cons (car a) x)) b)
	(pairs (cdr a) b)))

Then we could use this data structure with two-dimensional versions
of the usual higher order procedures.  For example:

(define (2dfilter pred s)
  (if (null? s)
      '()
      (cons (filter pred (car s))
	    (2dfilter pred (cdr s)))))


4.33  Quoted lazy lists

Instead of
        ((quoted? exp) (text-of-quotation exp))
we need a more complicated treatment to turn the ordinary lists
of the underlying Scheme into lazy lists.

        ((quoted? exp) (process-quotation (text-of-quotation exp) env))

(define (process-quotation quoted env)
  (if (pair? quoted)
      (lazy-cons (process-quotation (car quoted) env)
		 (process-quotation (cdr quoted) env)
		 env)
      quoted))

(define (lazy-cons x y env)
  (make-procedure '(m) (list (list 'm x y)) env))

or alternatively

(define (lazy-cons x y env)
  (apply (lookup-variable-value 'cons env)
	 (list x y)))

This lazy-cons is the below-the-line equivalent of the above-the-line
CONS on page 409.



MapReduce
=========

1(a).  We are given lines of text as the data, with book names as keys.
We're going to want to group together intermediate pairs containing a given
text word.  Since mapreduce groups the data based on the keys in the
intermediate pairs, we have to use a word from the input line as a key, and
use the key of the input pair as the value of the intermediate pair.  (This
is why it's called an "inverted" index.)

(define (index directory)
  (mapreduce (lambda (kv-pair)
	       (map (lambda (wd) (make-kv-pair wd (kv-key kv-pair)))
		    (kv-value kv-pair)))
	     cons
	     '()
	     directory))

However, this has duplicates; we'll need a slightly more complicated
reducer to get rid of them:

(define (adv-index directory)
  (mapreduce (lambda (kv-pair)
	       (map (lambda (wd) (make-kv-pair wd (kv-key kv-pair)))
		    (kv-value kv-pair)))

	     (LAMBDA (NEW OLD)
	       (IF (MEMBER NEW OLD)
		   OLD
		   (CONS NEW OLD)))
	     '()
	     directory))

1(b).  We just have to have the mapper filter out the undesired words.

(define (big-word-index directory N)
  (mapreduce (lambda (kv-pair)
	       (map (lambda (wd) (cons wd (kv-key kv-pair)))
		    (FILTER (LAMBDA (WD) (>= (COUNT WD) N))
			    (kv-value kv-pair))))
	     cons
	     '()
	     directory))

Note that we could use the same trick as in adv-index to get rid of duplicates.

2(a).  As in the word-count problem, we need intermediate pairs in which
all the values are 1, and the individual subject lines are used as keys.
The keys of the input data don't matter, just the values, which are those
4-tuples shown in the example.

(define subject-frequencies
  (mapreduce (lambda (kv-pair)
	       (list (make-kv-pair (caddr (kv-value kv-pair)) 1)))
	     +
	     0
	     "/sample-emails"))


2(b). The intermediate step here is just inversion: we want MapReduce to
sort by highest subject occurrence, so we'll make the keys subject line
occurrences:

(mapreduce (lambda (kvp)
	     (list (make-kv-pair (kv-value kvp) (kv-key kvp))))
	   cons
	   '()
	   subject-frequencies)

If we wanted the big numbers to be at the start, we could have negated
the counts:

(mapreduce (lambda (kvp)
	     (list (make-kv-pair (- (kv-value kvp)) (kv-key kvp))))
	   cons
	   '()
	   subject-frequencies)

We could then take the kv-values of the first ten elements of this stream,
and use that 

2(c) Intermediate kv-pairs are from-address, 1.

(mapreduce (lambda (kv-pair)
	     (if (member (caddr kv-pair) ten-most-common)
		 (list (make-kv-pair (car (kv-value kv-pair)) 1))
		 '()))
	   +
	   0
	   email-table-from-2a)


3.  The mapreduce algorithm actually has three parts: the mapping, then an
implicit sort, and then the reduction.  So in order to do just the mapping
or just the reduction, the sorting by intermediate key has to be unimportant.
In those situations, you could make a case for wanting a separate MAP or
GROUPREDUCE function.

But even then, bear in mind that it's hard to implement a parallel 
mapreduce, working with a distributed file system, efficiently.  The
implementation we use (Hadoop) is the result of a large group effort,
tuned up after a lot of experience using it.  So, instead of duplicating
all that effort to write separate map and groupreduce functions,
it would probably make more sense to have the mapreduce implementation
notice when the mapper argument is the identity function, or the reducer
argument is cons-stream, and treat those as built-in special cases.

4.  The mathematically correct answer is that the infinite stream of primes
can't be generated by a mapreduce operation, because you have to find
a new prime before you can filter out its multiples.  So each of the
parallel processes would have to know when another process finds a prime;
the processes couldn't be independent.  (This is why the SIEVE procedure in
the book uses explicit recursion for each prime, rather than calling
STREAM-MAP.)

But the engineering answer is different.  Remember that in lecture we only
needed the primes up to 7 in order to filter out all the non-primes up to
50.  In general, to filter the candidates up to N, we only need to know the
primes up to (SQRT N).

So, suppose we use a single processor (or just our brains) to find all the
primes up to 35.  We can then take the numbers from 36 to 35*35=1225,
split those up among however many processors we have, and let each processor
use the list of below-35 primes to filter its subset of the candidates.

Now we have a list of the primes up to 1225.  We can teach that list to all
the processors, and do a second mapreduce run to compute the primes up to
1225*1225 = 1,500,625.  (Bear in mind that this isn't a list of a million
primes; primes are pretty rare.  Exercise: What's the probability that a
positive integer isn't divisible by 2, 3, 5, or 7?  Primes are even rarer
than that!)  We can repeat this strategy as often as needed; the next pass
will get us the primes below a trillion, etc.




Extra for Experts
=================

4.31

Despite what the exercise says, there's no need to change the procedures that
determine the DEFINE syntax, because it doesn't check that the formal
parameters are symbols.  Even MAKE-PROCEDURE doesn't check.

The hard part is in procedure invocation.  The original metacircular evaluator
has this in the big COND in EVAL:

	((application? exp)
	 (mc-apply (MC-EVAL (operator exp) env)
		   (LIST-OF-VALUES (operands exp) env)))

The lazy evaluator in the book changes that to

        ((application? exp)
         (mc-apply (ACTUAL-VALUE (operator exp) env)
		   (operands exp)	; no LIST-OF-VALUES
		   ENV))		; added argument

(For this exercise, it's easier to work with the book's version than with
the slightly different alternative shown in the lecture notes.)

So now we're giving APPLY expressions rather than values, and we're also
giving APPLY an environment in which to evaluate or thunkify the values.
We don't have to make any change to the book's EVAL; the hard part is in
APPLY, in which we have to decide whether to evaluate or thunkify.

Here's the book's lazy APPLY:

(define (mc-apply procedure arguments env)
  (cond ((primitive-procedure? procedure)
         (apply-primitive-procedure
          procedure
          (LIST-OF-ARG-VALUES ARGUMENTS ENV)))	; ***
        ((compound-procedure? procedure)
         (eval-sequence
          (procedure-body procedure)
          (extend-environment
           (procedure-parameters procedure)
           (LIST-OF-DELAYED-ARGS ARGUMENTS ENV) ; ***
           (procedure-environment procedure))))
        (else
         (error
          "Unknown procedure type -- APPLY" procedure))))

The two commented lines handle evaluation, for primitive procedures, and
thunking, for non-primitive procedures.  It's the latter we have to change;
the args may be evaluated, thunked with memoization, or thunked without
memoization.  To make this decision, we have to look at the formal parameters
of the procedure we're calling.  So the second commented line above will
change to

           (PROCESS-ARGS arguments (PROCEDURE-PARAMETERS PROCEDURE) env)

Two things have changed; we're calling a not-yet-written procedure
PROCESS-ARGS instead of LIST-OF-DELAYED-ARGS, and we're giving that procedure
the formal parameters as well as the actual argument expressions.

One more thing has to change in APPLY:  Since the list returned by
PROCEDURE-PARAMETERS is no longer a list of symbols, but can now include
sublists such as (B LAZY), we have to extract the real formal parameter
names from it.  So the final version of APPLY is this:

(define (mc-apply procedure arguments env)
  (cond ((primitive-procedure? procedure)
         (apply-primitive-procedure
          procedure
          (list-of-arg-values arguments env)))
        ((compound-procedure? procedure)
         (eval-sequence
          (procedure-body procedure)
          (extend-environment
           (EXTRACT-NAMES (procedure-parameters procedure))		 ; ***
           (PROCESS-ARGS arguments (PROCEDURE-PARAMETERS PROCEDURE) env) ; ***
           (procedure-environment procedure))))
        (else
         (error
          "Unknown procedure type -- APPLY" procedure))))

Now comes the actual work, in EXTRACT-NAMES and in PROCESS-ARGS.

EXTRACT-NAMES takes as its argument a list such as
	(A (B LAZY) C (D LAZY-MEMO))
and returns a list with just the variable names:
	(A B C D)

(define (extract-names formals)
  (cond ((null? formals) '())
	((pair? (car formals))	; CAR is (VAR TYPE), so keep CAAR in result
	 (cons (caar formals) (extract-names (cdr formals))))
	(else (cons (car formals) (extract-names (cdr formals))))))

PROCESS-ARGS takes an argument list, let's say
	((+ 2 3) (- 4 5) (* 6 7) (/ 8 9))
and a parameter list, such as
	(A (B LAZY) C (D LAZY-MEMO))
and matches them up.  It pays no attention to the variable names in the
parameter list; it's only looking for LAZY or LAZY-MEMO type tags.  It returns
a list of argument values-and-thunks:
	(5 (THUNK-NOMEMO (- 4 5) <env>) 42 (THUNK-MEMO (/ 8 9) <env>))
where <env> represents an actual environment, not the word ENV.  The argument
expressions (+ 2 3) and (* 6 7) correspond to non-lazy parameters A and C,
so they've been evaluated; the other arguments have been turned into thunks
by combining them with a type-tag (THUNK-NOMEMO or THUNK-MEMO as appropriate)
and an environment.  Instead of the book's DELAY-IT procedure we have to use
two different procedures, DELAY-NOMEMO and DELAY-MEMO, to construct the thunks.

(define (process-args args formals env)
  (cond ((null? args) '())
	((null? formals)
	 (error "Too many arguments"))
	((pair? (car formals))
	 (cond ((eq? (cadar formals) 'lazy)
		(cons (delay-nomemo (car args) env)
		      (process-args (cdr args) (cdr formals) env)))
	       ((eq? (cadar formals) 'lazy-memo)
		(cons (delay-memo (car args) env)
		      (process-args (cdr args) (cdr formals) env)))
	       (else (error "Unrecognized parameter type" (cadar formals)))))
	(else (cons (EVAL (car args))
		    (process-args (cdr args) (cdr formals) env)))))

Note the call to EVAL in capital letters two lines up.  Should that be EVAL
or ACTUAL-VALUE?  The issue is what behavior we want when a procedure with a
non-lazy parameter is called with a thunk (created by calling some other
non-primitive procedure) as the argument:

	(define (foo x)
	  x)

	(define (baz (lazy x))
	  x)

	(define p (foo (baz (/ 1 0))))

What should happen?  FOO's argument is non-lazy, so we evaluate the argument
expression (BAZ (/ 1 0)).  BAZ's argument is lazy, so we make a thunk that
promises to compute (/ 1 0) later, and that becomes the argument to FOO.
If we use EVAL up there, as written, then FOO will get a thunk as its
argument, and will return the thunk, which will become the value of P.  If
we make it ACTUAL-VALUE, then the thunk will be forced, and we'll get an
error dividing by zero, and P won't get a value.

I think the procedure FOO probably doesn't care whether or not its argument is
a thunk, and therefore the argument shouldn't be forced.  If the return value
from FOO is used in some context where a real value is needed (for example,
if we said
	(foo (baz (/ 1 0)))
at the Scheme prompt instead of inside a DEFINE, then the value will be
forced.)  But you'd like to be able to write something like

	(define (cadr seq) (car (cdr seq)))

and if this is applied to a list of thunks, the result should be a
thunk, not the value promised by the thunk.

Perhaps there should be a third parameter type tag, so you could say

	(define (f a (b lazy) c (d lazy-memo) (e forced))
	  ...)

allowing the user to choose between EVAL and ACTUAL-VALUE here.  This would
add a COND clause in APPLY:

	       ((eq? (cadar formals) 'forced)
		(cons (actual-value (car args) env)
		      (process-args (cdr args) (cdr formals) env)))


Now we have to do a little data abstraction:

(define (delay-nomemo exp env)
  (list 'THUNK-NOMEMO exp env))

(define (delay-memo exp env)
  (list 'THUNK-MEMO exp env))

Note that the thunk constructors don't have to do any real memoization or
non-memoization work; they just construct thunks that "know" which kind they
are.  It's when the thunks are forced that we have to take the difference
into account:

(define (force-it obj)
  (cond ((THUNK-MEMO? obj)		; two kinds of thunk testers
         (let ((result (actual-value
                        (thunk-exp obj)
                        (thunk-env obj))))
           (set-car! obj 'evaluated-thunk)
           (set-car! (cdr obj) result)  ; replace exp with its value
           (set-cdr! (cdr obj) '())     ; for memoized thunk
           result))
	((THUNK-NOMEMO? OBJ)	; nomemo thunk is EVALed each time it's forced
	 (ACTUAL-VALUE (THUNK-EXP OBJ) (THUNK-ENV OBJ)))
        ((evaluated-thunk? obj)
         (thunk-value obj))
        (else obj)))

(define (thunk-memo? exp)
  (tagged-list? exp 'thunk-memo))

(define (thunk-nomemo? exp)
  (tagged-list exp 'thunk-nomemo))

Note that for both kinds of thunks we call ACTUAL-VALUE to cash in the promise;
the difference is that for a memoized thunk we remember the result, whereas for
a non-memoized thunk we don't.
</pre>
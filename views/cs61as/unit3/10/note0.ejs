<!-- Lecture Notes 10: Client/server paradigm, Concurrency -->

<p>
<b>Reading:</b>
Abelson &amp; Sussman, Section
<a href="http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-23.html">3.4</a>,
<a href="http://inst.eecs.berkeley.edu/~cs61as/reader/Therac-25.pdf">Therac-25</a>
article in reader

<p>
<b>&bull; Client/server programming paradigm</b>

<p>
Before networks, most programs ran on a single computer.  Today it's common
for programs to involve cooperation between computers.  The usual reason is
that you want to run a program on your computer that uses data located
elsewhere.  A common example is using a browser on
your computer to read a web page stored somewhere else.

<p>
To make this cooperation possible, <i>two </i> programs are actually
required:&nbsp;the <i>client </i> program on your personal computer and the <i>
server </i> program on the remote computer.  Sometimes the client and the server
are written by a single group, but often someone publishes a <i>standard </i>
document that allows any client to work with any server that follows the same
standard.  For example, you can use Mozilla, Netscape, or Internet Explorer to
read most web pages, because they all follow standards set by the World Wide Web
Consortium.

<p>
For this course we provide a sample client/server system, implementing a
simple Instant Message protocol.  The files are available in

<p>
<tt>  <pre>&#126;cs61as/lib/im-client.scm
&#126;cs61as/lib/im-server.scm
</pre></tt>

<p>
To use them, you must first start a server.  Load <tt>im-server.scm</tt> and
call the procedure <tt>im-server-start</tt>; it will print the IP (Internet
Protocol) address of the
machine you're using, along with another number, the <i>port </i> assigned
to the server.  Clients will use these numbers to connect to the server.
Port numbers are important because there might be more than one server program
running on the same computer, and also to keep track of connections from more
than one client.

<p>
(Why don't you need these numbers when using "real" network software?  You
don't need to know the IP address because your client software knows how to
connect to <i>nameservers </i> to translate the host names you give it into
addresses.  And most client/server protocols use fixed, <i>registered </i>
port numbers that are built into the software.  For example, web browsers use
port 80, while the <tt>ssh</tt> protocol you may use to connect to your class
account from home uses port 22.  But our sample client/server protocol doesn't
have a registered port number, so the operating system assigns a port to the
server when you start it.)

<p>
To connect to the server, load <tt>im-client.scm</tt> and call <tt>im-enroll</tt>
with the IP address and port number as arguments.  (Details are in this week's
lab assignment.)  Then use the <tt>im</tt> procedure to send a message to other
people connected to the same server.

<p>
This simple implementation uses the Scheme interpreter as its user interface;
you send messages by typing Scheme expressions.  Commercial Instant Message
clients have a more ornate user interface, that accept mouse clicks in windows
listing other clients to specify the recipient of a message.  But our version
is realistic in the way it uses the network; the IM client on your home
computer connects to a particular port on a particular server in order to use
the facility.  (The only difference is that a large commercial IM system will
have more than one server; your client connects to the one nearest you, and
the servers send messages among themselves to give the illusion of one big
server to which everyone is connected.)

<p>
In the news these days, client/server protocols are sometimes contrasted with
another approach called <i>peer-to-peer </i> networking, such as file-sharing
systems like Napster and Kazaa.  The distinction is social rather than
strictly technical.  In each individual transaction using a peer-to-peer
protocol, one machine is acting as a server and the other as a client.  What
makes it peer-to-peer networking is that any machine using the protocol can
play either role, unlike the more usual commercial networking idea in which
rich companies operate servers and ordinary people operate clients.

<p>

<p>

<p>
<b>Internet primitives in STk</b>

<p>
STk defines sockets, on systems which support them, as first class objects.
Sockets permit processes to communicate even if they are on different
machines. Sockets are useful for creating client-server applications.

<p>You aren't required to know anything about the details of internet
programming, but if you're interested, the STk networking primitives
are described <a href="static/course_material/91/92/stk-net.html">here</a>.

<p>
<font face="symbol"></font
> <b>Concurrency</b>

<p>
To work with the ideas in this section you should first

<p>
<tt>  <pre>(load "&#126;cs61as/lib/concurrent.scm")
</pre></tt>
in order to get the necessary Scheme extensions.

<p>
<b>Parallelism</b>

<p>
Many things we take for granted in ordinary programming become
problematic when there is any kind of parallelism involved.
These situations include

<p><ul>
<li>multiple processors (hardware) sharing data
<li>software multithreading (simulated parallelism)
<li>operating system input/output device handlers
</ul>

<p>This is the most important topic in CS&nbsp;162, the operating
systems course; here in 61AS we give only a brief introduction,
in the hope that when you see this topic for the second time
it'll be clearer as a result.

<p>
To see in simple terms what the problem is, think about the
Scheme expression

<p>
<tt>  <pre>(set! x (+ x 1))
</pre></tt>

<p>
As you'll learn in more detail in 61C, Scheme translates this
into a sequence of instructions to your computer.  The details
depend on the particular computer model, but it'll be something
like this:

<p>
<tt>  <pre>   lw   $8, x          ; Load a Word from memory location x
                       ; into processor register number 8.
   addi $8, 1          ; Add the Immediate value 1 to the register.
   sw   $8, x          ; Store the Word from register 8 back
                       ; into memory location x.
</pre></tt>

<p>
Ordinarily we would expect this sequence of instructions to have
the desired effect.  If the value of <tt>x</tt> was 100 before these
instructions, it should be 101 after them.

<p>
But imagine that this sequence of three instructions can be
interrupted by other events that come in the middle.  To be
specific, let's suppose that someone else is also trying to&nbsp;add 1 to <tt>x</tt>'s value.  Now we might have this sequence:

<p>
<tt>  <pre>
my process                       other process
----                             -----

lw   $8, x   [value is 100]
addi $8, 1   [value is 101]
                                 lw   $9, x   [value is 100]
                                 addi $9, 1   [value is 101]
                                 sw   $9, x   [stores 101]
sw   $8, x   [stores 101]
</pre></tt>

<p>
The ultimate value of <tt>x</tt> will be 101, instead of the correct 102.

<p>
The general idea we need to solve this problem is the <i>critical section</i>,
which means a sequence of instructions that mustn't be interrupted.  The
three instructions starting with the load and ending with the store are
a critical section.

<p>

<p>
Actually, we don't have to say that these instructions can't be
interrupted; the only condition we must enforce is that they can't
be interrupted by another process that uses the variable <tt>x</tt>.
It's okay if another process wants to add 1 to <tt>y</tt> meanwhile.
So we'd like to be able to say something like

<p>
<tt>  <pre>reserve x
lw      $8, x
addi    $8, 1
sw      $8, x
release x
</pre></tt>

<p>
<b>Levels of Abstraction</b>

<p>
Computers don't really have instructions quite like <tt>reserve</tt>
and <tt>release</tt>, but we'll see that they do provide similar
mechanisms.  A typical programming environment includes concurrency
control mechanisms at three levels of abstraction:

<p>
<tt>  <pre>
SICP name        What's protected           Provided by
---              ------                     ----

serializer       high level abstraction     programming language
                  (procedure, object, ...)

mutex            critical section           operating system

test-and-set!    one atomic                 hardware
                   state transition
</pre></tt>

<p>
The serializer and the mutex are, in SICP, abstract data types.  There is
a constructor <tt>make-serializer</tt> that's implemented using a mutex, and a
constructor <tt>make-mutex</tt> that's implemented using <tt>test-and-set!</tt>,
which is a (simulated, in our case) hardware instruction.

<p>
<b>Serializers</b>

<p>
  For now, let's look at how this idea can be expressed
at a higher level of abstraction, in a Scheme program.

<p>
<tt>  <pre>(define x-protector (make-serializer))

(define protected-increment-x (x-protector (lambda () (set! x (+ x 1)))))

&#62; x
100
&#62; (protected-increment-x)
&#62; x
101
</pre></tt>

<p>
We introduce an abstraction called a <i>serializer</i>.  This is a procedure
that takes as its argument another procedure (call it <tt>proc</tt>).  The
serializer returns a new procedure (call it <tt>protected-proc</tt>).  When
invoked, <tt>protected-proc</tt> invokes <tt>proc</tt>, but only if the <i>
same </i> serializer is not already in use by another protected procedure.
<tt>Proc</tt> can have any number of arguments, and <tt>protected-proc</tt> will
take the same arguments and return the same value.

<p>
There can be many different serializers, all in operation at once, but each
one can't be doing two things at once.  So if we say

<p>
<tt>  <pre>(define x-protector (make-serializer))
(define y-protector (make-serializer))
</pre></tt>

<p>
<tt>  <pre>(parallel-execute (x-protector (lambda () (set! x (+ x 1))))
                  (y-protector (lambda () (set! y (+ y 1)))))
</pre></tt>

<p>
then both tasks can run at the same time; it doesn't matter
how their machine instructions are interleaved.  But if we
say

<p>
<tt>  <pre>(parallel-execute (x-protector (lambda () (set! x (+ x 1))))
                  (x-protector (lambda () (set! x (+ x 1)))))
</pre></tt>

<p>
then, since we're using the same serializer in both tasks, the
serializer will ensure that they don't overlap in time.

<p>
I've introduced a new primitive procedure, <tt>parallel-execute</tt>.  It
takes any number of arguments, each of which is a
procedure of no arguments, and invokes them them, in
parallel rather than in sequence.  (This isn't a standard part
of Scheme, but an extension for this section of the textbook.)

<p>
You may be wondering about the need for all those <tt>(lambda&nbsp;()...)</tt>
notations.  Since a serializer isn't a special form, it can't take
an expression as argument.  Instead we must give it a procedure
that it can invoke.

<p>
<b>Programming Considerations</b>

<p>
Even with serializers, it's not easy to do a good job of writing
programs that deal successfully with concurrency.  In fact, all of
the operating systems in widespread use today have bugs in this
area; Unix systems, for example, are expected to crash every
month or two because of concurrency bugs.

<p>
To make the discussion concrete, let's think about an airline
reservation system, which serves thousands of simultaneous
users around the world.  Here are the things that can go wrong:

<p>
<font face="symbol"></font
> <b>Incorrect results.</b>  The worst problem is if the
same seat is reserved for two different people.  Just as in the
case of adding 1 to <tt>x</tt>, the reservation system must first
find a vacant seat, then mark that seat as occupied.  That sequence
of reading and then modifying the database must be protected.

<p>
<font face="symbol"></font
> <b>Inefficiency.</b>  One very simple way to ensure
correct results is to use a single serializer to protect the
entire reservation database, so that only one person could make
a request at a time.  But this is an unacceptable solution;
thousands of people are waiting to reserve seats, mostly not
for the same flight.

<p>
<font face="symbol"></font
> <b>Deadlock.</b>  Suppose that someone wants to travel
to a city for which there is no direct flight.  We must make
sure that we can reserve a seat on flight A and a seat on
connecting flight B on the same day, before we commit to either
reservation.  This probably means that we need to use <i>two </i>
serializers at the same time, one for each flight.  Suppose we
say something like

<p>
<tt>  <pre>(serializer-A (serializer-B (lambda () ...))))
</pre></tt>

<p>
Meanwhile someone else says

<p>
<tt>  <pre>(serializer-B (serializer-A (lambda () ...))))
</pre></tt>

<p>
The timing could work out so that we get serializer A, the
other person gets serializer B, and then we are each stuck
waiting for the other one.

<p>
<font face="symbol"></font
> <b>Unfairness.</b>  This isn't an issue in every
situation, but sometimes you want to avoid a solution to the
deadlock problem that always gives a certain process priority
over some other one.  If the high-priority process is greedy,
the lower-priority process might never get its turn at the
shared data.

<p>

<p>
<b>Implementing Serializers</b>

<p>
A serializer is a high-level abstraction.  How do we make it work?
Here is an <i>incorrect </i> attempt to implement serializers:

<p>
<tt>  <pre>;;;;;                        In file cs61as/lectures/3.4/bad-serial.scm
(define (make-serializer)
  (let ((in-use? #f))
    (lambda (proc)
      (define (protected-proc . args)
	(if in-use?
	    (begin
	     (wait-a-while)                 ; Never mind how to do that.
	     (apply protected-proc args))   ; Try again.
	    (begin
	     (set! in-use? #t)        ; Don't let anyone else in.
	     (apply proc args)        ; Call the original procedure.
	     (set! in-use? #f))))     ; Finished, let others in again.
      protected-proc)))
</pre></tt>

<p>
This is a little complicated, so concentrate on the important parts.
In particular, never mind about the <i>scheduling </i> aspect of
parallelism-how we can ask this process to wait a while before
trying again if the serializer is already in use.  And never mind
the stuff about <tt>apply</tt>, which is needed only so that we can
serialize procedures with any number of arguments.

<p>
The part to focus on is this:

<p>
<tt>  <pre>	(if in-use?
	    .......         ; wait and try again
	    (begin
	     (set! in-use #t)        ; Don't let anyone else in.
	     (apply proc args)       ; Call the original procedure.
	     (set! in-use #f)))      ; Finished, let others in again.
</pre></tt>

<p>
The intent of this code is that it first checks to see if the
serializer is already in use.  If not, we claim the serializer
by setting <tt>in-use</tt> true, do our job, and then release the
serializer.

<p>
The problem is that this sequence of events is subject to the
same parallelism problems as the procedure we're trying to protect!
What if we check the value of <tt>in-use</tt>, discover that it's false,
and right at that moment another process sneaks in and grabs the
serializer?  In order to make this work we'd have to have another
serializer protecting this one, and a third serializer protecting
the second one, and so on.

<p>
<i>There is no easy way to avoid this problem by clever programming
tricks within the competing processes</i>.  We need help at the level
of the underlying machinery that provides the parallelism: the
hardware and/or the operating system.  That underlying level must
provide a <i>guaranteed atomic </i> operation with which we can
test the old value of <tt>in-use</tt> and change it to a new value
with no possibility of another process intervening.  (It turns out that
there is a very tricky software algorithm to generate guaranteed
atomic test-and-set, but in practice, there is almost always hardware
support for parallelism.  Look up "Peterson's algorithm" in Wikipedia
if you want to see the software solution.)

<p>
The textbook assumes the existence of a procedure called
<tt>test-and-set!</tt>&nbsp;with this guarantee of atomicity.  Although
there is a pseudo-implementation on page 312, that procedure
won't really work, for the same reason that my pseudo-implementation
of <tt>make-serializer</tt> won't work.  What you have to imagine
is that <tt>test-and-set!</tt>&nbsp;is a single instruction in the
computer's hardware, comparable to the Load Word instructions
and so on that I started with.  (This is a realistic assumption;
modern computers do provide some such hardware mechanism,
precisely for the reasons we're discussing now.)

<p>
<b>The Mutex</b>

<p>
The book uses an intermediate level of abstraction between
the serializer and the atomic hardware capability, called
a <i>mutex</i>.  What's the difference between a mutex and
a serializer?  The serializer provides, as an abstraction,
a protected operation, without requiring the programmer to
think about the mechanism by which it's protected.  The
mutex exposes the sequence of events.  Just as my incorrect
implementation said

<p>
<tt>  <pre>    (set! in-use #t)
    (apply proc args)
    (set! in-use #f)
</pre></tt>

<p>
the correct version uses a similar sequence

<p>
<tt>  <pre>    (mutex 'acquire)
    (apply proc args)
    (mutex 'release)
</pre></tt>

<p>
By the way, all of the versions in these notes have another bug;
I've simplified the discussion by ignoring the problem of return
values.  We want the value returned by <tt>protected-proc</tt> to be
the same as the value returned by the original <tt>proc</tt>, even
though the call to <tt>proc</tt> isn't the last step.  Therefore
the correct implementation is

<p>
<tt>  <pre>    (mutex 'acquire)
    (let ((result (apply proc args)))
      (mutex 'release)
      result)
</pre></tt>

<p>
as in the book's implementation on page 311.


<p>
<b>&bull; Software reliability: the Therac failures</b>

The following notes are more terse than usual, so I highly recommend
that you watch the lecture (below) even if you don't usually watch them.

<p><center><iframe width="420" height="345" src="http://www.youtube.com/embed/nxX-aAvZbmM" frameborder="0" allowfullscreen></iframe></center>


<p>
<ul>
<li>6 accidents, 4 deaths
<ul>
<li>but 100s of lives saved
</ul>
<li>no bad guys (cf. Ford Pinto case)
<li>Software doesn't degrade like hardware
<ul>
<li>but it rots anyway
<li>but it has much greater complexity
</ul>
cf. Star Wars (birth of CPSR)
<li>Continuum of life-or-deathness: Clearly Therac yes, clearly video game no.
<ul><li>But what about OS, spreadsheet, etc.?</ul>
<li>Therac bugs
<ul>
<li>no atomic test and set
<li>hardware interlocks removed
<li>UI problems:
<ul><li>cursor position
<li>defaults
<li>too many error messages
</ul>
<li>documentation
<li>organizational response
<ul><li>easy to see after the fact, but problems are inherent in
organizations (esp. ones that can be sued)</ul>
<li>Solutions
<ul>
<li>redundancy
<li>fail soft (work despite bugs)
<li>audit trail
<li>Software Engineering (an attitude about programming)
<ul type="disc"><li>Design techniques
<ul type="circle">
<li>modularization (cf. OOP)
<li>understand concurrency (semaphores)
<li>analyze invariants
</ul>
<li>Verification techniques
<ul type="circle">
<li>correctness proofs
<ul><li>(can't be perfect because of halting theorem but still useful)</ul>
<li>automatic analysis in compiler
</ul>
<li>Debugging techniques
<ul type="circle">
<li>black box vs. glass box
<li>don't break old code with new fix
<li>introduce bugs on purpose to analyze results downstream
<li>debug by subtraction, not addition
</ul></ul></ul></ul></p>